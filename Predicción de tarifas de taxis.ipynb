{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-06-08 13:59:39 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# medir tiempos\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![output](tiempo_secuencial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando la data usando Pyspark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2021-06-08 13:59:40 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Modulo para encontrar pyspark\n",
    "import findspark\n",
    "#findspark.init(\"/usr/local/spark/spark-3.1.1-bin-hadoop2.7\")    #para linux\n",
    "findspark.init()                                                 #para windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.19:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ModeloML</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=ModeloML>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.52 s (started: 2021-06-08 13:59:40 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# importamos pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "# Variable de configuración\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"ModeloML\")\n",
    "# iniciamos un contexto spark (solo se ejecuta uno. Para ejecutar otra vez , reiniciar el kernel)\n",
    "sc = SparkContext(conf = conf)\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.8 s (started: 2021-06-08 13:59:44 -05:00)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark import SQLContext\n",
    "# le pasamos el contexto anterior\n",
    "sqlContext = SQLContext(sc)\n",
    "dfspark = sqlContext.read.format('csv').option(\"header\",\"true\").option(\"inferSchema\",\"true\").load('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      "\n",
      "time: 16 ms (started: 2021-06-08 14:00:12 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Esquema de los datos\n",
    "dfspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55423856"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.16 s (started: 2021-06-08 14:00:12 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Total de cantidad de datos\n",
    "cant_total=dfspark.count()\n",
    "cant_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-06-08 14:00:18 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Tomando una muestra del 4% del total\n",
    "dfspark_sample = dfspark.sample(fraction = 0.04, withReplacement = False, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apartir de aqui trabajamos con una muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2219408"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.19 s (started: 2021-06-08 14:00:18 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de datos para la muestra\n",
    "cant_muestra=dfspark_sample.count()\n",
    "cant_muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de la data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procederá a eliminar la columna con la característica \"key\", debido a que contiene datos innecesarios para lograr el objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-06-08 14:00:25 -05:00)\n"
     ]
    }
   ],
   "source": [
    "dfspark_sample = dfspark_sample.drop('key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Eliminando Valores Nulos de la tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 187 ms (started: 2021-06-08 14:00:25 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# fare_amount (costo de viaje) no nulos\n",
    "dfspark_sample = dfspark_sample.filter(\"fare_amount is not NULL\")\n",
    "# passenger (número de pasajeros) no nulos\n",
    "dfspark_sample = dfspark_sample.filter(\"passenger_count is not NULL\")\n",
    "# pickup_datetime (fecha y hora de incio de viaje) no nulos\n",
    "dfspark_sample = dfspark_sample.filter(\"pickup_datetime is not NULL\")\n",
    "# pickup (longitud y latitud de inicio de viaje) no nulos\n",
    "dfspark_sample = dfspark_sample.filter(\"pickup_longitude is not NULL\")\n",
    "dfspark_sample = dfspark_sample.filter(\"pickup_latitude is not NULL\")\n",
    "# dropoff (longitud y laitud de fin de viaje) no nulos\n",
    "dfspark_sample = dfspark_sample.filter(\"dropoff_longitude is not NULL\")\n",
    "dfspark_sample = dfspark_sample.filter(\"dropoff_latitude is not NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2219390"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.3 s (started: 2021-06-08 14:00:25 -05:00)\n"
     ]
    }
   ],
   "source": [
    "ncant_muestra=dfspark_sample.count()\n",
    "ncant_muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Eliminado valores nan y duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de filas eliminadas de la muestra:  18\n",
      "time: 27 s (started: 2021-06-08 14:00:48 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# tabla sin valores nan, sin duplicados\n",
    "dfspark_sample=dfspark_sample.na.drop().dropDuplicates()\n",
    "# cantidad de  data sin nulos ni nan\n",
    "cantnn_muestra=dfspark_sample.count()\n",
    "print(\"Cantidad de filas eliminadas de la muestra: \",cant_muestra-cantnn_muestra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[fare_amount: double, pickup_datetime: string, pickup_longitude: double, pickup_latitude: double, dropoff_longitude: double, dropoff_latitude: double, passenger_count: int]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 78 ms (started: 2021-06-08 14:01:15 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# que la data persista en memoria, acelera algunos procesos.\n",
    "dfspark_sample.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 328 ms (started: 2021-06-08 14:01:15 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.6 s (started: 2021-06-08 14:01:16 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# casteamos a pandas\n",
    "summary=dfspark_sample.describe([\"pickup_longitude\",\n",
    "                                 \"pickup_latitude\",\n",
    "                                 \"dropoff_longitude\",\n",
    "                                 \"dropoff_latitude\",\n",
    "                                 \"passenger_count\",\n",
    "                                 \"fare_amount\"]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>2219390</td>\n",
       "      <td>2219390</td>\n",
       "      <td>2219390</td>\n",
       "      <td>2219390</td>\n",
       "      <td>2219390</td>\n",
       "      <td>2219390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>-72.50355231460159</td>\n",
       "      <td>39.91779369363991</td>\n",
       "      <td>-72.50697030839864</td>\n",
       "      <td>39.91850726486102</td>\n",
       "      <td>1.6851959322156087</td>\n",
       "      <td>11.352503967306385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>13.098889190132796</td>\n",
       "      <td>9.821243657749829</td>\n",
       "      <td>13.244549098861283</td>\n",
       "      <td>10.317917931047642</td>\n",
       "      <td>1.3377753769552685</td>\n",
       "      <td>42.449025079080954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>-3366.527908</td>\n",
       "      <td>-3488.079513</td>\n",
       "      <td>-3366.527908</td>\n",
       "      <td>-3488.079513</td>\n",
       "      <td>0</td>\n",
       "      <td>-52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>2497.117435</td>\n",
       "      <td>2964.163855</td>\n",
       "      <td>3211.57975</td>\n",
       "      <td>3333.304575</td>\n",
       "      <td>208</td>\n",
       "      <td>61550.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary    pickup_longitude    pickup_latitude   dropoff_longitude  \\\n",
       "0   count             2219390            2219390             2219390   \n",
       "1    mean  -72.50355231460159  39.91779369363991  -72.50697030839864   \n",
       "2  stddev  13.098889190132796  9.821243657749829  13.244549098861283   \n",
       "3     min        -3366.527908       -3488.079513        -3366.527908   \n",
       "4     max         2497.117435        2964.163855          3211.57975   \n",
       "\n",
       "     dropoff_latitude     passenger_count         fare_amount  \n",
       "0             2219390             2219390             2219390  \n",
       "1   39.91850726486102  1.6851959322156087  11.352503967306385  \n",
       "2  10.317917931047642  1.3377753769552685  42.449025079080954  \n",
       "3        -3488.079513                   0               -52.0  \n",
       "4         3333.304575                 208            61550.86  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2021-06-08 14:01:43 -05:00)\n"
     ]
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|passenger_count|  count|\n",
      "+---------------+-------+\n",
      "|              1|1535882|\n",
      "|              6|  47132|\n",
      "|              3|  97242|\n",
      "|              5| 157254|\n",
      "|              4|  47158|\n",
      "|              7|      1|\n",
      "|              2| 326983|\n",
      "|              0|   7734|\n",
      "|            208|      4|\n",
      "+---------------+-------+\n",
      "\n",
      "time: 1.95 s (started: 2021-06-08 14:01:43 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Agrupación por cantidad de pasajeros.\n",
    "dfspark_sample.groupBy(\"passenger_count\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones :\n",
    "1. Valores de passenger_count imposibles , como 34,49,51,129,208.\n",
    "2. Precios demasiados elevados debido a la cantidad de pasajeros y negativo(imposible).\n",
    "3. Cantidad de datos en la que el precio es menor a o igual a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|min(pickup_longitude)|\n",
      "+---------------------+\n",
      "|         -3366.527908|\n",
      "+---------------------+\n",
      "\n",
      "+---------------------+\n",
      "|max(pickup_longitude)|\n",
      "+---------------------+\n",
      "|          2497.117435|\n",
      "+---------------------+\n",
      "\n",
      "+----------------------+\n",
      "|min(dropoff_longitude)|\n",
      "+----------------------+\n",
      "|          -3366.527908|\n",
      "+----------------------+\n",
      "\n",
      "+----------------------+\n",
      "|max(dropoff_longitude)|\n",
      "+----------------------+\n",
      "|            3211.57975|\n",
      "+----------------------+\n",
      "\n",
      "+--------------------+\n",
      "|min(pickup_latitude)|\n",
      "+--------------------+\n",
      "|        -3488.079513|\n",
      "+--------------------+\n",
      "\n",
      "+--------------------+\n",
      "|max(pickup_latitude)|\n",
      "+--------------------+\n",
      "|         2964.163855|\n",
      "+--------------------+\n",
      "\n",
      "+---------------------+\n",
      "|min(dropoff_latitude)|\n",
      "+---------------------+\n",
      "|         -3488.079513|\n",
      "+---------------------+\n",
      "\n",
      "+---------------------+\n",
      "|max(dropoff_latitude)|\n",
      "+---------------------+\n",
      "|          3333.304575|\n",
      "+---------------------+\n",
      "\n",
      "time: 3.26 s (started: 2021-06-08 14:01:45 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# mínimo y máximo para longitud del subconjunto de datos\n",
    "long_min_i=dfspark_sample.agg({'pickup_longitude': 'min'}).show()\n",
    "long_max_i=dfspark_sample.agg({'pickup_longitude': 'max'}).show()\n",
    "long_min_f=dfspark_sample.agg({'dropoff_longitude': 'min'}).show()\n",
    "long_max_f=dfspark_sample.agg({'dropoff_longitude': 'max'}).show()\n",
    "\n",
    "# mínimo y máximo para para latitud del subconjuntos de datos\n",
    "lat_min_i=dfspark_sample.agg({'pickup_latitude': 'min'}).show()\n",
    "lat_max_i=dfspark_sample.agg({'pickup_latitude': 'max'}).show()\n",
    "lat_min_f=dfspark_sample.agg({'dropoff_latitude': 'min'}).show()\n",
    "lat_max_f=dfspark_sample.agg({'dropoff_latitude': 'max'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones:\n",
    "1. Valores para longitud imposibles, ya que longitud varía entre -90 y 90\n",
    "2. Valores para latitud imposibles, ya que latitud varía entre -180 y 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformación de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2021-06-08 14:01:49 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar passenger_count de 0-9\n",
    "dfspark_sample = dfspark_sample.filter(\"passenger_count < 10\")\n",
    "# Selecionar fare_amount mayor a 0\n",
    "dfspark_sample = dfspark_sample.filter(\"fare_amount >= 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|passenger_count|  count|\n",
      "+---------------+-------+\n",
      "|              1|1535823|\n",
      "|              6|  47129|\n",
      "|              3|  97238|\n",
      "|              5| 157246|\n",
      "|              4|  47155|\n",
      "|              7|      1|\n",
      "|              2| 326972|\n",
      "|              0|   7734|\n",
      "+---------------+-------+\n",
      "\n",
      "time: 2.01 s (started: 2021-06-08 14:01:49 -05:00)\n"
     ]
    }
   ],
   "source": [
    "dfspark_sample.groupBy(\"passenger_count\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47 ms (started: 2021-06-08 14:01:51 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Filtrando valores grandes para longitud, de tal manera que solo se considerará valores correctos.\n",
    "dfspark_sample = dfspark_sample.filter(\"pickup_longitude < 180 and pickup_longitude > -180\" )\n",
    "dfspark_sample = dfspark_sample.filter(\"dropoff_longitude < 180 and dropoff_longitude > -180\")\n",
    "dfspark_sample = dfspark_sample.filter(\"pickup_latitude < 90 and pickup_latitude > -90\" )\n",
    "dfspark_sample = dfspark_sample.filter(\"dropoff_latitude < 90 and dropoff_latitude > -90\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.61 s (started: 2021-06-08 14:01:51 -05:00)\n"
     ]
    }
   ],
   "source": [
    "summary_new=dfspark_sample.describe([\"pickup_longitude\",\n",
    "                                 \"pickup_latitude\",\n",
    "                                 \"dropoff_longitude\",\n",
    "                                 \"dropoff_latitude\"]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>-72.49600158477304</td>\n",
       "      <td>39.91679455251933</td>\n",
       "      <td>-72.50229931133802</td>\n",
       "      <td>39.91968272022599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>10.463045755203852</td>\n",
       "      <td>6.112153680008393</td>\n",
       "      <td>10.439016533276373</td>\n",
       "      <td>6.104146217099324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>-121.91499328613281</td>\n",
       "      <td>-74.017222</td>\n",
       "      <td>-121.9151840209961</td>\n",
       "      <td>-74.177303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>40.840962</td>\n",
       "      <td>74.007413</td>\n",
       "      <td>73.93996</td>\n",
       "      <td>74.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary     pickup_longitude    pickup_latitude   dropoff_longitude  \\\n",
       "0   count              2219173            2219173             2219173   \n",
       "1    mean   -72.49600158477304  39.91679455251933  -72.50229931133802   \n",
       "2  stddev   10.463045755203852  6.112153680008393  10.439016533276373   \n",
       "3     min  -121.91499328613281         -74.017222  -121.9151840209961   \n",
       "4     max            40.840962          74.007413            73.93996   \n",
       "\n",
       "    dropoff_latitude  \n",
       "0            2219173  \n",
       "1  39.91968272022599  \n",
       "2  6.104146217099324  \n",
       "3         -74.177303  \n",
       "4              74.95  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2021-06-08 14:01:52 -05:00)\n"
     ]
    }
   ],
   "source": [
    "summary_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2021-06-08 14:01:52 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Agregamos columnas de diferencias.\n",
    "from pyspark.sql.functions import abs\n",
    "dfspark_sample = dfspark_sample.withColumn(\"dif_latitude\",\n",
    "                                           abs(dfspark_sample['dropoff_latitude']-dfspark_sample['pickup_latitude']))\n",
    "dfspark_sample = dfspark_sample.withColumn(\"dif_longitude\",\n",
    "                                           abs(dfspark_sample['dropoff_longitude']-dfspark_sample['pickup_longitude']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 63 ms (started: 2021-06-08 14:01:52 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Creamos la función para hallar la distancia entre dos puntos geográficos\n",
    "import math\n",
    "from pyspark.sql.functions import udf, array, col\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "def haversine(x):\n",
    "    lat1=x[0]\n",
    "    lon1=x[1]\n",
    "    lat2=x[2]\n",
    "    lon2=x[3]\n",
    "    \n",
    "    rad=math.pi/180\n",
    "    dlat=lat2-lat1\n",
    "    dlon=lon2-lon1\n",
    "    R=6372.795477598\n",
    "    a=(math.sin(rad*dlat/2))**2 + math.cos(rad*lat1)*math.cos(rad*lat2)*(math.sin(rad*dlon/2))**2\n",
    "    distancia=2*R*math.asin(math.sqrt(a))\n",
    "    return distancia\n",
    "\n",
    "distancia_udf = udf(lambda z: haversine(z), FloatType())\n",
    "#spark.udf.register('distancia_udf', distancia_udf)\n",
    "dfspark_sample = dfspark_sample.withColumn('distancia', distancia_udf(array('pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude')))                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| distancia|\n",
      "+----------+\n",
      "| 1.8683056|\n",
      "| 1.8191968|\n",
      "|  1.145462|\n",
      "| 1.0793539|\n",
      "| 1.1367035|\n",
      "|  2.424119|\n",
      "|  3.829884|\n",
      "| 1.0900514|\n",
      "| 5.5276585|\n",
      "|  3.122764|\n",
      "| 2.3627946|\n",
      "| 5.3667502|\n",
      "| 1.3431213|\n",
      "|  9.317738|\n",
      "|  5.013023|\n",
      "| 4.6022677|\n",
      "| 1.1546545|\n",
      "| 20.964258|\n",
      "| 0.8852747|\n",
      "|0.17227533|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "time: 656 ms (started: 2021-06-08 14:01:52 -05:00)\n"
     ]
    }
   ],
   "source": [
    "dfspark_sample.select(col('distancia')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear dos columnas día de la semana y hora del viaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-06-08 14:01:53 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# funciones que me ayudarán en la transformación.\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import calendar\n",
    "def dia(dia):\n",
    "    if dia == 1:\n",
    "        return 'lunes'\n",
    "    if dia == 2:\n",
    "        return 'martes'\n",
    "    if dia == 3:\n",
    "        return 'miércoles'\n",
    "    if dia == 4:\n",
    "        return 'jueves'\n",
    "    if dia == 5:\n",
    "        return 'viernes'\n",
    "    if dia == 6:\n",
    "        return 'sábado'\n",
    "    if dia == 7:\n",
    "        return 'domingo'\n",
    "    if dia < 1 or dia > 7:\n",
    "        return \n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "def dia_semana(row):\n",
    "    fecha , hora , utc = row.split(\" \")\n",
    "    formato_fecha = \"%Y-%m-%d\"\n",
    "    dia_semana = datetime.isoweekday(datetime.strptime(fecha,formato_fecha))\n",
    "    return dia_semana\n",
    "\n",
    "def hora(row):\n",
    "    fecha , hora , utc = row.split(\" \")\n",
    "    formato_hora = \"%H:%M:%S\"\n",
    "    hora = datetime.strptime(hora,formato_hora).hour\n",
    "    return hora\n",
    "    \n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "# convirtiendo las funciones en funciones UDF\n",
    "udf_dia_semana= udf( lambda z : dia_semana(z))\n",
    "udf_hora= udf( lambda z : hora(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47 ms (started: 2021-06-08 14:01:53 -05:00)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "dfspark_sample = dfspark_sample.withColumn('dia_semana', \n",
    "                                           udf_dia_semana(dfspark_sample['pickup_datetime'] )  )\n",
    "dfspark_sample = dfspark_sample.withColumn('hora', \n",
    "                                           udf_hora(dfspark_sample['pickup_datetime'] )  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2021-06-08 14:01:53 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Castear dia de la semana y hora\n",
    "dfspark_sample = dfspark_sample.withColumn(\"dia_semana\",\n",
    "                                           dfspark_sample[\"dia_semana\"].cast(\"Integer\"))\n",
    "dfspark_sample = dfspark_sample.withColumn(\"hora\",\n",
    "                                           dfspark_sample[\"hora\"].cast(\"Integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- dif_latitude: double (nullable = true)\n",
      " |-- dif_longitude: double (nullable = true)\n",
      " |-- distancia: float (nullable = true)\n",
      " |-- dia_semana: integer (nullable = true)\n",
      " |-- hora: integer (nullable = true)\n",
      "\n",
      "time: 0 ns (started: 2021-06-08 14:01:53 -05:00)\n"
     ]
    }
   ],
   "source": [
    "dfspark_sample.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observación: En este punto la data estaria totalmente ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadística de las nuevas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 26s (started: 2021-06-08 14:01:53 -05:00)\n"
     ]
    }
   ],
   "source": [
    "clean_summary=dfspark_sample.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>dif_latitude</th>\n",
       "      <th>dif_longitude</th>\n",
       "      <th>dia_semana</th>\n",
       "      <th>hora</th>\n",
       "      <th>distancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>-72.49600158477304</td>\n",
       "      <td>39.91679455251933</td>\n",
       "      <td>-72.50229931133802</td>\n",
       "      <td>39.91968272022599</td>\n",
       "      <td>1.6848177226381178</td>\n",
       "      <td>11.353258637339264</td>\n",
       "      <td>0.09229194952135444</td>\n",
       "      <td>0.16173652033227268</td>\n",
       "      <td>4.042932660049487</td>\n",
       "      <td>13.512919452426647</td>\n",
       "      <td>19.38368660013694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>10.463045755203852</td>\n",
       "      <td>6.112153680008393</td>\n",
       "      <td>10.439016533276373</td>\n",
       "      <td>6.104146217099324</td>\n",
       "      <td>1.3087759778931933</td>\n",
       "      <td>42.45082368146176</td>\n",
       "      <td>1.699312422647234</td>\n",
       "      <td>3.1986543317178917</td>\n",
       "      <td>1.9490730146054265</td>\n",
       "      <td>6.517990756130113</td>\n",
       "      <td>365.85874227507634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>-121.91499328613281</td>\n",
       "      <td>-74.017222</td>\n",
       "      <td>-121.9151840209961</td>\n",
       "      <td>-74.177303</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>40.840962</td>\n",
       "      <td>74.007413</td>\n",
       "      <td>73.93996</td>\n",
       "      <td>74.95</td>\n",
       "      <td>7</td>\n",
       "      <td>61550.86</td>\n",
       "      <td>73.961092</td>\n",
       "      <td>89.483332</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>9952.922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary     pickup_longitude    pickup_latitude   dropoff_longitude  \\\n",
       "0   count              2219173            2219173             2219173   \n",
       "1    mean   -72.49600158477304  39.91679455251933  -72.50229931133802   \n",
       "2  stddev   10.463045755203852  6.112153680008393  10.439016533276373   \n",
       "3     min  -121.91499328613281         -74.017222  -121.9151840209961   \n",
       "4     max            40.840962          74.007413            73.93996   \n",
       "\n",
       "    dropoff_latitude     passenger_count         fare_amount  \\\n",
       "0            2219173             2219173             2219173   \n",
       "1  39.91968272022599  1.6848177226381178  11.353258637339264   \n",
       "2  6.104146217099324  1.3087759778931933   42.45082368146176   \n",
       "3         -74.177303                   0                 0.0   \n",
       "4              74.95                   7            61550.86   \n",
       "\n",
       "          dif_latitude        dif_longitude          dia_semana  \\\n",
       "0              2219173              2219173             2219173   \n",
       "1  0.09229194952135444  0.16173652033227268   4.042932660049487   \n",
       "2    1.699312422647234   3.1986543317178917  1.9490730146054265   \n",
       "3                  0.0                  0.0                   1   \n",
       "4            73.961092            89.483332                   7   \n",
       "\n",
       "                 hora           distancia  \n",
       "0             2219173             2219173  \n",
       "1  13.512919452426647   19.38368660013694  \n",
       "2   6.517990756130113  365.85874227507634  \n",
       "3                   0                 0.0  \n",
       "4                  23            9952.922  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32 ms (started: 2021-06-08 14:03:20 -05:00)\n"
     ]
    }
   ],
   "source": [
    "columnas = [\"summary\",\n",
    "            \"pickup_longitude\",\n",
    "            \"pickup_latitude\",\n",
    "            \"dropoff_longitude\",\n",
    "            \"dropoff_latitude\",\n",
    "            \"passenger_count\",\n",
    "            \"fare_amount\",\n",
    "            \"dif_latitude\",\n",
    "            \"dif_longitude\",\n",
    "            \"dia_semana\",\n",
    "            \"hora\",\n",
    "            \"distancia\"]\n",
    "clean_summary[columnas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlación de los atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_old=[\"pickup_longitude\",\n",
    "         \"pickup_latitude\",\n",
    "         \"dropoff_longitude\",\n",
    "         \"dropoff_latitude\",\n",
    "         \"passenger_count\"]\n",
    "col_new=[\"dif_latitude\",\n",
    "         \"dif_longitude\",\n",
    "         \"dia_semana\",\n",
    "         \"hora\"]\n",
    "col_pred = [\"fare_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación en un vector\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "inputCols = col_old+col_new+col_pred\n",
    "assembler = VectorAssembler( inputCols=inputCols, outputCol=\"col_corr\")\n",
    "dfspark_corr = assembler.transform(dfspark_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspark_corr=dfspark_corr.select('col_corr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estudiar la correlación\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "dfspark_corr= Correlation.corr(dfspark_corr, 'col_corr','pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import DenseMatrix, Vectors\n",
    "#type(dfspark_cor.collect()[0][0]) # denseMatrix\n",
    "# Pasamos la matrix como un array.\n",
    "array_corr=dfspark_corr.collect()[0][0].toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_corr= pd.DataFrame(array_corr, columns=inputCols, index=inputCols)\n",
    "mask = ~(pdf_corr>-0.3) | ~(pdf_corr<0.3)\n",
    "round(pdf_corr,10).style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observación:\n",
    "###### La variable a predecir fare_amount itnee muy baja correlación con las demás variables. Su mayor correlación es con passenger_count y hora. Pero si observamos correlación entre las demás variables. Definitivamente no podemos utilizar un modelo lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de la data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasamos toda la data a Pandas\n",
    "pandasData = dfspark_sample.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manera alternativa de pasar la data a Pandas\n",
    "# import pandas as pd\n",
    "# from pyspark.sql import DataFrame\n",
    "\n",
    "# # Wrapper for seamless Spark's serialisation\n",
    "# def spark_to_pandas(spark_df: DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     PySpark toPandas realisation using mapPartitions\n",
    "#     much faster than vanilla version\n",
    "#     fork: https://gist.github.com/lucidyan/1e5d9e490a101cdc1c2ed901568e082b\n",
    "#     origin: https://gist.github.com/joshlk/871d58e01417478176e7\n",
    "#     :param spark_df:\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def _map_to_pandas(rdds) -> list:\n",
    "#         \"\"\" Needs to be here due to pickling issues \"\"\"\n",
    "#         return [pd.DataFrame(list(rdds))]\n",
    "\n",
    "#     def _to_pandas(df: DataFrame, n_partitions: int = None) -> pd.DataFrame:\n",
    "#         \"\"\"\n",
    "#         Returns the contents of `df` as a local `pandas.DataFrame` in a speedy fashion. The DataFrame is\n",
    "#         repartitioned if `n_partitions` is passed.\n",
    "#         :param df:\n",
    "#         :param n_partitions:\n",
    "#         :return:\n",
    "#         \"\"\"\n",
    "#         if n_partitions is not None:\n",
    "#             df = df.repartition(n_partitions)\n",
    "#         df_pand = df.rdd.mapPartitions(_map_to_pandas).collect()  # type: pd.DataFrame\n",
    "#         df_pand = pd.concat(df_pand)\n",
    "#         df_pand.columns = df.columns\n",
    "#         return df_pand\n",
    "\n",
    "#     return _to_pandas(spark_df)\n",
    "\n",
    "# pandasData = spark_to_pandas(dfspark_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostrando la data\n",
    "display(pandasData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"ticks\" , color_codes = True)\n",
    "var = [\"dia_semana\"]\n",
    "# 1 inches = 96px\n",
    "g = sns.pairplot(pandasData[:10], vars=var, diag_kind=\"hist\", hue='dia_semana', height=4, aspect=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cuanto de la variable objetivo va variando segun los dias de la semana\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "carac1=pandasData['dia_semana']\n",
    "objet=pandasData['fare_amount']\n",
    "plt.plot(carac1, objet, 'o')\n",
    "plt.xlabel(\"Característica dia de la semana\")\n",
    "plt.ylabel(\"Objetivo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#como los pasajeros se distribuyen a traves de las horas\n",
    "pandasData.groupby('hora')['passenger_count'].sum().plot(kind='barh',legend='Reverse',figsize=(10,10))\n",
    "plt.xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#como se reparten los pasajeros en funcion de la hora\n",
    "pandasData.passenger_count.groupby(pandasData.hora).sum().plot(kind='pie',cmap='Paired',figsize=(12,8))\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dispersion de las características\n",
    "caracteristicas=pandasData[['fare_amount','pickup_longitude','pickup_latitude','dropoff_longitude']]\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "g= sns.pairplot(caracteristicas,hue='fare_amount',palette='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cerramos la sesión spark\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
