{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-06-08 13:59:39 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# medir tiempos\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![output](tiempo_secuencial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando la data usando Pyspark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modulo para encontrar pyspark\n",
    "import findspark\n",
    "#findspark.init(\"/usr/local/spark/spark-3.1.1-bin-hadoop2.7\")    #para linux\n",
    "findspark.init()                                                 #para windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.4:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ModeloML</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=ModeloML>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importamos pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "# Variable de configuración\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"ModeloML\")\n",
    "# iniciamos un contexto spark (solo se ejecuta uno. Para ejecutar otra vez , reiniciar el kernel)\n",
    "sc = SparkContext(conf = conf)\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark import SQLContext\n",
    "# le pasamos el contexto anterior\n",
    "sqlContext = SQLContext(sc)\n",
    "dfspark = sqlContext.read.format('csv').option(\"header\",\"true\").option(\"inferSchema\",\"true\").load('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Esquema de los datos\n",
    "dfspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55423856"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total de cantidad de datos\n",
    "cant_total=dfspark.count()\n",
    "cant_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomando una muestra del 4% del total\n",
    "dfspark_sample = dfspark.sample(fraction = 0.04, withReplacement = False, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apartir de aqui trabajamos con una muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2219408"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de datos para la muestra\n",
    "cant_muestra=dfspark_sample.count()\n",
    "cant_muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de la data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procederá a eliminar la columna con la característica \"key\", debido a que contiene datos innecesarios para lograr el objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspark_sample = dfspark_sample.drop('key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Eliminando Valores Nulos de la tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fare_amount (costo de viaje) no nulos\n",
    "dfspark_sample = dfspark_sample.filter(\"fare_amount is not NULL\")\n",
    "# passenger (número de pasajeros) no nulos\n",
    "dfspark_sample = dfspark_sample.filter(\"passenger_count is not NULL\")\n",
    "# pickup_datetime (fecha y hora de incio de viaje) no nulos\n",
    "dfspark_sample = dfspark_sample.filter(\"pickup_datetime is not NULL\")\n",
    "# pickup (longitud y latitud de inicio de viaje) no nulos\n",
    "dfspark_sample = dfspark_sample.filter(\"pickup_longitude is not NULL\")\n",
    "dfspark_sample = dfspark_sample.filter(\"pickup_latitude is not NULL\")\n",
    "# dropoff (longitud y laitud de fin de viaje) no nulos\n",
    "dfspark_sample = dfspark_sample.filter(\"dropoff_longitude is not NULL\")\n",
    "dfspark_sample = dfspark_sample.filter(\"dropoff_latitude is not NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2219390"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncant_muestra=dfspark_sample.count()\n",
    "ncant_muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Eliminado valores nan y duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de filas eliminadas de la muestra:  18\n"
     ]
    }
   ],
   "source": [
    "# tabla sin valores nan, sin duplicados\n",
    "dfspark_sample=dfspark_sample.na.drop().dropDuplicates()\n",
    "# cantidad de  data sin nulos ni nan\n",
    "cantnn_muestra=dfspark_sample.count()\n",
    "print(\"Cantidad de filas eliminadas de la muestra: \",cant_muestra-cantnn_muestra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[fare_amount: double, pickup_datetime: string, pickup_longitude: double, pickup_latitude: double, dropoff_longitude: double, dropoff_latitude: double, passenger_count: int]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# que la data persista en memoria, acelera algunos procesos.\n",
    "dfspark_sample.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casteamos a pandas\n",
    "summary=dfspark_sample.describe([\"pickup_longitude\",\n",
    "                                 \"pickup_latitude\",\n",
    "                                 \"dropoff_longitude\",\n",
    "                                 \"dropoff_latitude\",\n",
    "                                 \"passenger_count\",\n",
    "                                 \"fare_amount\"]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>2219390</td>\n",
       "      <td>2219390</td>\n",
       "      <td>2219390</td>\n",
       "      <td>2219390</td>\n",
       "      <td>2219390</td>\n",
       "      <td>2219390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>-72.50355231460159</td>\n",
       "      <td>39.91779369363991</td>\n",
       "      <td>-72.50697030839864</td>\n",
       "      <td>39.91850726486102</td>\n",
       "      <td>1.6851959322156087</td>\n",
       "      <td>11.352503967306385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>13.098889190132796</td>\n",
       "      <td>9.821243657749829</td>\n",
       "      <td>13.244549098861283</td>\n",
       "      <td>10.317917931047642</td>\n",
       "      <td>1.3377753769552685</td>\n",
       "      <td>42.449025079080954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>-3366.527908</td>\n",
       "      <td>-3488.079513</td>\n",
       "      <td>-3366.527908</td>\n",
       "      <td>-3488.079513</td>\n",
       "      <td>0</td>\n",
       "      <td>-52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>2497.117435</td>\n",
       "      <td>2964.163855</td>\n",
       "      <td>3211.57975</td>\n",
       "      <td>3333.304575</td>\n",
       "      <td>208</td>\n",
       "      <td>61550.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary    pickup_longitude    pickup_latitude   dropoff_longitude  \\\n",
       "0   count             2219390            2219390             2219390   \n",
       "1    mean  -72.50355231460159  39.91779369363991  -72.50697030839864   \n",
       "2  stddev  13.098889190132796  9.821243657749829  13.244549098861283   \n",
       "3     min        -3366.527908       -3488.079513        -3366.527908   \n",
       "4     max         2497.117435        2964.163855          3211.57975   \n",
       "\n",
       "     dropoff_latitude     passenger_count         fare_amount  \n",
       "0             2219390             2219390             2219390  \n",
       "1   39.91850726486102  1.6851959322156087  11.352503967306385  \n",
       "2  10.317917931047642  1.3377753769552685  42.449025079080954  \n",
       "3        -3488.079513                   0               -52.0  \n",
       "4         3333.304575                 208            61550.86  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|passenger_count|  count|\n",
      "+---------------+-------+\n",
      "|              1|1535882|\n",
      "|              6|  47132|\n",
      "|              3|  97242|\n",
      "|              5| 157254|\n",
      "|              4|  47158|\n",
      "|              7|      1|\n",
      "|              2| 326983|\n",
      "|              0|   7734|\n",
      "|            208|      4|\n",
      "+---------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupación por cantidad de pasajeros.\n",
    "dfspark_sample.groupBy(\"passenger_count\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones :\n",
    "1. Valores de passenger_count imposibles , como 34,49,51,129,208.\n",
    "2. Precios demasiados elevados debido a la cantidad de pasajeros y negativo(imposible).\n",
    "3. Cantidad de datos en la que el precio es menor a o igual a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|min(pickup_longitude)|\n",
      "+---------------------+\n",
      "|         -3366.527908|\n",
      "+---------------------+\n",
      "\n",
      "+---------------------+\n",
      "|max(pickup_longitude)|\n",
      "+---------------------+\n",
      "|          2497.117435|\n",
      "+---------------------+\n",
      "\n",
      "+----------------------+\n",
      "|min(dropoff_longitude)|\n",
      "+----------------------+\n",
      "|          -3366.527908|\n",
      "+----------------------+\n",
      "\n",
      "+----------------------+\n",
      "|max(dropoff_longitude)|\n",
      "+----------------------+\n",
      "|            3211.57975|\n",
      "+----------------------+\n",
      "\n",
      "+--------------------+\n",
      "|min(pickup_latitude)|\n",
      "+--------------------+\n",
      "|        -3488.079513|\n",
      "+--------------------+\n",
      "\n",
      "+--------------------+\n",
      "|max(pickup_latitude)|\n",
      "+--------------------+\n",
      "|         2964.163855|\n",
      "+--------------------+\n",
      "\n",
      "+---------------------+\n",
      "|min(dropoff_latitude)|\n",
      "+---------------------+\n",
      "|         -3488.079513|\n",
      "+---------------------+\n",
      "\n",
      "+---------------------+\n",
      "|max(dropoff_latitude)|\n",
      "+---------------------+\n",
      "|          3333.304575|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mínimo y máximo para longitud del subconjunto de datos\n",
    "long_min_i=dfspark_sample.agg({'pickup_longitude': 'min'}).show()\n",
    "long_max_i=dfspark_sample.agg({'pickup_longitude': 'max'}).show()\n",
    "long_min_f=dfspark_sample.agg({'dropoff_longitude': 'min'}).show()\n",
    "long_max_f=dfspark_sample.agg({'dropoff_longitude': 'max'}).show()\n",
    "\n",
    "# mínimo y máximo para para latitud del subconjuntos de datos\n",
    "lat_min_i=dfspark_sample.agg({'pickup_latitude': 'min'}).show()\n",
    "lat_max_i=dfspark_sample.agg({'pickup_latitude': 'max'}).show()\n",
    "lat_min_f=dfspark_sample.agg({'dropoff_latitude': 'min'}).show()\n",
    "lat_max_f=dfspark_sample.agg({'dropoff_latitude': 'max'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones:\n",
    "1. Valores para longitud imposibles, ya que longitud varía entre -90 y 90\n",
    "2. Valores para latitud imposibles, ya que latitud varía entre -180 y 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformación de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar passenger_count de 0-9\n",
    "dfspark_sample = dfspark_sample.filter(\"passenger_count < 10\")\n",
    "# Selecionar fare_amount mayor a 0\n",
    "dfspark_sample = dfspark_sample.filter(\"fare_amount >= 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|passenger_count|  count|\n",
      "+---------------+-------+\n",
      "|              1|1535823|\n",
      "|              6|  47129|\n",
      "|              3|  97238|\n",
      "|              5| 157246|\n",
      "|              4|  47155|\n",
      "|              7|      1|\n",
      "|              2| 326972|\n",
      "|              0|   7734|\n",
      "+---------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfspark_sample.groupBy(\"passenger_count\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando valores grandes para longitud, de tal manera que solo se considerará valores correctos.\n",
    "dfspark_sample = dfspark_sample.filter(\"pickup_longitude < 180 and pickup_longitude > -180\" )\n",
    "dfspark_sample = dfspark_sample.filter(\"dropoff_longitude < 180 and dropoff_longitude > -180\")\n",
    "dfspark_sample = dfspark_sample.filter(\"pickup_latitude < 90 and pickup_latitude > -90\" )\n",
    "dfspark_sample = dfspark_sample.filter(\"dropoff_latitude < 90 and dropoff_latitude > -90\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_new=dfspark_sample.describe([\"pickup_longitude\",\n",
    "                                 \"pickup_latitude\",\n",
    "                                 \"dropoff_longitude\",\n",
    "                                 \"dropoff_latitude\"]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>-72.49600158477304</td>\n",
       "      <td>39.91679455251933</td>\n",
       "      <td>-72.50229931133802</td>\n",
       "      <td>39.91968272022599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>10.463045755203852</td>\n",
       "      <td>6.112153680008393</td>\n",
       "      <td>10.439016533276373</td>\n",
       "      <td>6.104146217099324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>-121.91499328613281</td>\n",
       "      <td>-74.017222</td>\n",
       "      <td>-121.9151840209961</td>\n",
       "      <td>-74.177303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>40.840962</td>\n",
       "      <td>74.007413</td>\n",
       "      <td>73.93996</td>\n",
       "      <td>74.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary     pickup_longitude    pickup_latitude   dropoff_longitude  \\\n",
       "0   count              2219173            2219173             2219173   \n",
       "1    mean   -72.49600158477304  39.91679455251933  -72.50229931133802   \n",
       "2  stddev   10.463045755203852  6.112153680008393  10.439016533276373   \n",
       "3     min  -121.91499328613281         -74.017222  -121.9151840209961   \n",
       "4     max            40.840962          74.007413            73.93996   \n",
       "\n",
       "    dropoff_latitude  \n",
       "0            2219173  \n",
       "1  39.91968272022599  \n",
       "2  6.104146217099324  \n",
       "3         -74.177303  \n",
       "4              74.95  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos columnas de diferencias.\n",
    "from pyspark.sql.functions import abs\n",
    "dfspark_sample = dfspark_sample.withColumn(\"dif_latitude\",\n",
    "                                           abs(dfspark_sample['dropoff_latitude']-dfspark_sample['pickup_latitude']))\n",
    "dfspark_sample = dfspark_sample.withColumn(\"dif_longitude\",\n",
    "                                           abs(dfspark_sample['dropoff_longitude']-dfspark_sample['pickup_longitude']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la función para hallar la distancia entre dos puntos geográficos\n",
    "import math\n",
    "from pyspark.sql.functions import udf, array, col\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "def haversine(x):\n",
    "    lat1=x[0]\n",
    "    lon1=x[1]\n",
    "    lat2=x[2]\n",
    "    lon2=x[3]\n",
    "    \n",
    "    rad=math.pi/180\n",
    "    dlat=lat2-lat1\n",
    "    dlon=lon2-lon1\n",
    "    R=6372.795477598\n",
    "    a=(math.sin(rad*dlat/2))**2 + math.cos(rad*lat1)*math.cos(rad*lat2)*(math.sin(rad*dlon/2))**2\n",
    "    distancia=2*R*math.asin(math.sqrt(a))\n",
    "    return distancia\n",
    "\n",
    "distancia_udf = udf(lambda z: haversine(z), FloatType())\n",
    "#spark.udf.register('distancia_udf', distancia_udf)\n",
    "dfspark_sample = dfspark_sample.withColumn('distancia', distancia_udf(array('pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude')))                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| distancia|\n",
      "+----------+\n",
      "| 1.8683056|\n",
      "| 1.8191968|\n",
      "|  1.145462|\n",
      "| 1.0793539|\n",
      "| 1.1367035|\n",
      "|  2.424119|\n",
      "|  3.829884|\n",
      "| 1.0900514|\n",
      "| 5.5276585|\n",
      "|  3.122764|\n",
      "| 2.3627946|\n",
      "| 5.3667502|\n",
      "| 1.3431213|\n",
      "|  9.317738|\n",
      "|  5.013023|\n",
      "| 4.6022677|\n",
      "| 1.1546545|\n",
      "| 20.964258|\n",
      "| 0.8852747|\n",
      "|0.17227533|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfspark_sample.select(col('distancia')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear dos columnas día de la semana y hora del viaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones que me ayudarán en la transformación.\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import calendar\n",
    "def dia(dia):\n",
    "    if dia == 1:\n",
    "        return 'lunes'\n",
    "    if dia == 2:\n",
    "        return 'martes'\n",
    "    if dia == 3:\n",
    "        return 'miércoles'\n",
    "    if dia == 4:\n",
    "        return 'jueves'\n",
    "    if dia == 5:\n",
    "        return 'viernes'\n",
    "    if dia == 6:\n",
    "        return 'sábado'\n",
    "    if dia == 7:\n",
    "        return 'domingo'\n",
    "    if dia < 1 or dia > 7:\n",
    "        return \n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "def dia_semana(row):\n",
    "    fecha , hora , utc = row.split(\" \")\n",
    "    formato_fecha = \"%Y-%m-%d\"\n",
    "    dia_semana = datetime.isoweekday(datetime.strptime(fecha,formato_fecha))\n",
    "    return dia_semana\n",
    "\n",
    "def hora(row):\n",
    "    fecha , hora , utc = row.split(\" \")\n",
    "    formato_hora = \"%H:%M:%S\"\n",
    "    hora = datetime.strptime(hora,formato_hora).hour\n",
    "    return hora\n",
    "    \n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "# convirtiendo las funciones en funciones UDF\n",
    "udf_dia_semana= udf( lambda z : dia_semana(z))\n",
    "udf_hora= udf( lambda z : hora(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "dfspark_sample = dfspark_sample.withColumn('dia_semana', \n",
    "                                           udf_dia_semana(dfspark_sample['pickup_datetime'] )  )\n",
    "dfspark_sample = dfspark_sample.withColumn('hora', \n",
    "                                           udf_hora(dfspark_sample['pickup_datetime'] )  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Castear dia de la semana y hora\n",
    "dfspark_sample = dfspark_sample.withColumn(\"dia_semana\",\n",
    "                                           dfspark_sample[\"dia_semana\"].cast(\"Integer\"))\n",
    "dfspark_sample = dfspark_sample.withColumn(\"hora\",\n",
    "                                           dfspark_sample[\"hora\"].cast(\"Integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- dif_latitude: double (nullable = true)\n",
      " |-- dif_longitude: double (nullable = true)\n",
      " |-- distancia: float (nullable = true)\n",
      " |-- dia_semana: integer (nullable = true)\n",
      " |-- hora: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfspark_sample.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observación: En este punto la data estaria totalmente ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadística de las nuevas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_summary=dfspark_sample.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>dif_latitude</th>\n",
       "      <th>dif_longitude</th>\n",
       "      <th>dia_semana</th>\n",
       "      <th>hora</th>\n",
       "      <th>distancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "      <td>2219173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>-72.49600158477304</td>\n",
       "      <td>39.91679455251933</td>\n",
       "      <td>-72.50229931133802</td>\n",
       "      <td>39.91968272022599</td>\n",
       "      <td>1.6848177226381178</td>\n",
       "      <td>11.353258637339264</td>\n",
       "      <td>0.09229194952135444</td>\n",
       "      <td>0.16173652033227268</td>\n",
       "      <td>4.042932660049487</td>\n",
       "      <td>13.512919452426647</td>\n",
       "      <td>19.38368660013694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>10.463045755203852</td>\n",
       "      <td>6.112153680008393</td>\n",
       "      <td>10.439016533276373</td>\n",
       "      <td>6.104146217099324</td>\n",
       "      <td>1.3087759778931933</td>\n",
       "      <td>42.45082368146176</td>\n",
       "      <td>1.699312422647234</td>\n",
       "      <td>3.1986543317178917</td>\n",
       "      <td>1.9490730146054265</td>\n",
       "      <td>6.517990756130113</td>\n",
       "      <td>365.85874227507634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>-121.91499328613281</td>\n",
       "      <td>-74.017222</td>\n",
       "      <td>-121.9151840209961</td>\n",
       "      <td>-74.177303</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>40.840962</td>\n",
       "      <td>74.007413</td>\n",
       "      <td>73.93996</td>\n",
       "      <td>74.95</td>\n",
       "      <td>7</td>\n",
       "      <td>61550.86</td>\n",
       "      <td>73.961092</td>\n",
       "      <td>89.483332</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>9952.922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary     pickup_longitude    pickup_latitude   dropoff_longitude  \\\n",
       "0   count              2219173            2219173             2219173   \n",
       "1    mean   -72.49600158477304  39.91679455251933  -72.50229931133802   \n",
       "2  stddev   10.463045755203852  6.112153680008393  10.439016533276373   \n",
       "3     min  -121.91499328613281         -74.017222  -121.9151840209961   \n",
       "4     max            40.840962          74.007413            73.93996   \n",
       "\n",
       "    dropoff_latitude     passenger_count         fare_amount  \\\n",
       "0            2219173             2219173             2219173   \n",
       "1  39.91968272022599  1.6848177226381178  11.353258637339264   \n",
       "2  6.104146217099324  1.3087759778931933   42.45082368146176   \n",
       "3         -74.177303                   0                 0.0   \n",
       "4              74.95                   7            61550.86   \n",
       "\n",
       "          dif_latitude        dif_longitude          dia_semana  \\\n",
       "0              2219173              2219173             2219173   \n",
       "1  0.09229194952135444  0.16173652033227268   4.042932660049487   \n",
       "2    1.699312422647234   3.1986543317178917  1.9490730146054265   \n",
       "3                  0.0                  0.0                   1   \n",
       "4            73.961092            89.483332                   7   \n",
       "\n",
       "                 hora           distancia  \n",
       "0             2219173             2219173  \n",
       "1  13.512919452426647   19.38368660013694  \n",
       "2   6.517990756130113  365.85874227507634  \n",
       "3                   0                 0.0  \n",
       "4                  23            9952.922  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnas = [\"summary\",\n",
    "            \"pickup_longitude\",\n",
    "            \"pickup_latitude\",\n",
    "            \"dropoff_longitude\",\n",
    "            \"dropoff_latitude\",\n",
    "            \"passenger_count\",\n",
    "            \"fare_amount\",\n",
    "            \"dif_latitude\",\n",
    "            \"dif_longitude\",\n",
    "            \"dia_semana\",\n",
    "            \"hora\",\n",
    "            \"distancia\"]\n",
    "clean_summary[columnas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlación de los atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_old=[\"pickup_longitude\",\n",
    "         \"pickup_latitude\",\n",
    "         \"dropoff_longitude\",\n",
    "         \"dropoff_latitude\",\n",
    "         \"passenger_count\"]\n",
    "col_new=[\"dif_latitude\",\n",
    "         \"dif_longitude\",\n",
    "         \"dia_semana\",\n",
    "         \"hora\"]\n",
    "col_pred = [\"fare_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación en un vector\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "inputCols = col_old+col_new+col_pred\n",
    "assembler = VectorAssembler( inputCols=inputCols, outputCol=\"col_corr\")\n",
    "dfspark_corr = assembler.transform(dfspark_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspark_corr=dfspark_corr.select('col_corr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estudiar la correlación\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "dfspark_corr= Correlation.corr(dfspark_corr, 'col_corr','pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import DenseMatrix, Vectors\n",
    "#type(dfspark_cor.collect()[0][0]) # denseMatrix\n",
    "# Pasamos la matrix como un array.\n",
    "array_corr=dfspark_corr.collect()[0][0].toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_dc6d0_row0_col0,#T_dc6d0_row1_col1,#T_dc6d0_row2_col2,#T_dc6d0_row3_col3,#T_dc6d0_row4_col4,#T_dc6d0_row5_col5,#T_dc6d0_row6_col6,#T_dc6d0_row7_col7,#T_dc6d0_row8_col8,#T_dc6d0_row9_col9{\n",
       "            background-color:  #023858;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_dc6d0_row0_col1,#T_dc6d0_row0_col4,#T_dc6d0_row1_col0,#T_dc6d0_row1_col4,#T_dc6d0_row1_col5,#T_dc6d0_row1_col6,#T_dc6d0_row1_col9,#T_dc6d0_row2_col3,#T_dc6d0_row2_col4,#T_dc6d0_row3_col2,#T_dc6d0_row3_col4,#T_dc6d0_row3_col9,#T_dc6d0_row5_col4,#T_dc6d0_row6_col4,#T_dc6d0_row7_col8,#T_dc6d0_row8_col7,#T_dc6d0_row8_col9{\n",
       "            background-color:  #fff7fb;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row0_col2,#T_dc6d0_row2_col0{\n",
       "            background-color:  #023e62;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_dc6d0_row0_col3,#T_dc6d0_row1_col2,#T_dc6d0_row3_col0,#T_dc6d0_row8_col4{\n",
       "            background-color:  #fcf4fa;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row0_col5,#T_dc6d0_row0_col6{\n",
       "            background-color:  #d1d2e6;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row0_col7,#T_dc6d0_row1_col8,#T_dc6d0_row2_col7,#T_dc6d0_row3_col8{\n",
       "            background-color:  #f2ecf5;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row0_col8,#T_dc6d0_row5_col7,#T_dc6d0_row5_col8,#T_dc6d0_row6_col8,#T_dc6d0_row9_col7{\n",
       "            background-color:  #f3edf5;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row0_col9,#T_dc6d0_row2_col9,#T_dc6d0_row4_col9,#T_dc6d0_row7_col9,#T_dc6d0_row9_col4{\n",
       "            background-color:  #fef6fb;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row1_col3,#T_dc6d0_row3_col1{\n",
       "            background-color:  #023d60;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_dc6d0_row1_col7,#T_dc6d0_row2_col8,#T_dc6d0_row3_col7,#T_dc6d0_row6_col7,#T_dc6d0_row9_col8{\n",
       "            background-color:  #f4edf6;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row2_col1{\n",
       "            background-color:  #fdf5fa;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row2_col5,#T_dc6d0_row2_col6{\n",
       "            background-color:  #d3d4e7;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row3_col5,#T_dc6d0_row3_col6,#T_dc6d0_row5_col9,#T_dc6d0_row6_col9{\n",
       "            background-color:  #fef6fa;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row4_col0,#T_dc6d0_row4_col1,#T_dc6d0_row4_col2,#T_dc6d0_row4_col3,#T_dc6d0_row7_col0,#T_dc6d0_row7_col1,#T_dc6d0_row7_col3,#T_dc6d0_row8_col0,#T_dc6d0_row8_col1,#T_dc6d0_row8_col2,#T_dc6d0_row9_col0,#T_dc6d0_row9_col1,#T_dc6d0_row9_col3{\n",
       "            background-color:  #76aad0;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row4_col5,#T_dc6d0_row7_col5,#T_dc6d0_row8_col5,#T_dc6d0_row9_col6{\n",
       "            background-color:  #ede8f3;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row4_col6,#T_dc6d0_row4_col7,#T_dc6d0_row7_col6,#T_dc6d0_row8_col6{\n",
       "            background-color:  #eee9f3;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row4_col8{\n",
       "            background-color:  #f1ebf4;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row5_col0{\n",
       "            background-color:  #529bc7;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row5_col1{\n",
       "            background-color:  #91b5d6;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row5_col2{\n",
       "            background-color:  #569dc8;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row5_col3,#T_dc6d0_row6_col1{\n",
       "            background-color:  #8fb4d6;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row5_col6,#T_dc6d0_row6_col5{\n",
       "            background-color:  #034a74;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_dc6d0_row6_col0{\n",
       "            background-color:  #509ac6;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row6_col2{\n",
       "            background-color:  #549cc7;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row6_col3{\n",
       "            background-color:  #8eb3d5;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row7_col2,#T_dc6d0_row8_col3,#T_dc6d0_row9_col2{\n",
       "            background-color:  #75a9cf;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row7_col4{\n",
       "            background-color:  #faf2f8;\n",
       "            color:  #000000;\n",
       "        }#T_dc6d0_row9_col5{\n",
       "            background-color:  #ece7f2;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_dc6d0_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >pickup_longitude</th>        <th class=\"col_heading level0 col1\" >pickup_latitude</th>        <th class=\"col_heading level0 col2\" >dropoff_longitude</th>        <th class=\"col_heading level0 col3\" >dropoff_latitude</th>        <th class=\"col_heading level0 col4\" >passenger_count</th>        <th class=\"col_heading level0 col5\" >dif_latitude</th>        <th class=\"col_heading level0 col6\" >dif_longitude</th>        <th class=\"col_heading level0 col7\" >dia_semana</th>        <th class=\"col_heading level0 col8\" >hora</th>        <th class=\"col_heading level0 col9\" >fare_amount</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_dc6d0_level0_row0\" class=\"row_heading level0 row0\" >pickup_longitude</th>\n",
       "                        <td id=\"T_dc6d0_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_dc6d0_row0_col1\" class=\"data row0 col1\" >-0.979316</td>\n",
       "                        <td id=\"T_dc6d0_row0_col2\" class=\"data row0 col2\" >0.953046</td>\n",
       "                        <td id=\"T_dc6d0_row0_col3\" class=\"data row0 col3\" >-0.940270</td>\n",
       "                        <td id=\"T_dc6d0_row0_col4\" class=\"data row0 col4\" >0.000166</td>\n",
       "                        <td id=\"T_dc6d0_row0_col5\" class=\"data row0 col5\" >0.144987</td>\n",
       "                        <td id=\"T_dc6d0_row0_col6\" class=\"data row0 col6\" >0.154172</td>\n",
       "                        <td id=\"T_dc6d0_row0_col7\" class=\"data row0 col7\" >0.002333</td>\n",
       "                        <td id=\"T_dc6d0_row0_col8\" class=\"data row0 col8\" >-0.002262</td>\n",
       "                        <td id=\"T_dc6d0_row0_col9\" class=\"data row0 col9\" >0.002182</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dc6d0_level0_row1\" class=\"row_heading level0 row1\" >pickup_latitude</th>\n",
       "                        <td id=\"T_dc6d0_row1_col0\" class=\"data row1 col0\" >-0.979316</td>\n",
       "                        <td id=\"T_dc6d0_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_dc6d0_row1_col2\" class=\"data row1 col2\" >-0.940902</td>\n",
       "                        <td id=\"T_dc6d0_row1_col3\" class=\"data row1 col3\" >0.961188</td>\n",
       "                        <td id=\"T_dc6d0_row1_col4\" class=\"data row1 col4\" >-0.001066</td>\n",
       "                        <td id=\"T_dc6d0_row1_col5\" class=\"data row1 col5\" >-0.136213</td>\n",
       "                        <td id=\"T_dc6d0_row1_col6\" class=\"data row1 col6\" >-0.126502</td>\n",
       "                        <td id=\"T_dc6d0_row1_col7\" class=\"data row1 col7\" >-0.003780</td>\n",
       "                        <td id=\"T_dc6d0_row1_col8\" class=\"data row1 col8\" >0.002227</td>\n",
       "                        <td id=\"T_dc6d0_row1_col9\" class=\"data row1 col9\" >-0.002081</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dc6d0_level0_row2\" class=\"row_heading level0 row2\" >dropoff_longitude</th>\n",
       "                        <td id=\"T_dc6d0_row2_col0\" class=\"data row2 col0\" >0.953046</td>\n",
       "                        <td id=\"T_dc6d0_row2_col1\" class=\"data row2 col1\" >-0.940902</td>\n",
       "                        <td id=\"T_dc6d0_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "                        <td id=\"T_dc6d0_row2_col3\" class=\"data row2 col3\" >-0.980122</td>\n",
       "                        <td id=\"T_dc6d0_row2_col4\" class=\"data row2 col4\" >0.000169</td>\n",
       "                        <td id=\"T_dc6d0_row2_col5\" class=\"data row2 col5\" >0.133518</td>\n",
       "                        <td id=\"T_dc6d0_row2_col6\" class=\"data row2 col6\" >0.138657</td>\n",
       "                        <td id=\"T_dc6d0_row2_col7\" class=\"data row2 col7\" >0.002700</td>\n",
       "                        <td id=\"T_dc6d0_row2_col8\" class=\"data row2 col8\" >-0.002691</td>\n",
       "                        <td id=\"T_dc6d0_row2_col9\" class=\"data row2 col9\" >0.002457</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dc6d0_level0_row3\" class=\"row_heading level0 row3\" >dropoff_latitude</th>\n",
       "                        <td id=\"T_dc6d0_row3_col0\" class=\"data row3 col0\" >-0.940270</td>\n",
       "                        <td id=\"T_dc6d0_row3_col1\" class=\"data row3 col1\" >0.961188</td>\n",
       "                        <td id=\"T_dc6d0_row3_col2\" class=\"data row3 col2\" >-0.980122</td>\n",
       "                        <td id=\"T_dc6d0_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "                        <td id=\"T_dc6d0_row3_col4\" class=\"data row3 col4\" >-0.001481</td>\n",
       "                        <td id=\"T_dc6d0_row3_col5\" class=\"data row3 col5\" >-0.126487</td>\n",
       "                        <td id=\"T_dc6d0_row3_col6\" class=\"data row3 col6\" >-0.116139</td>\n",
       "                        <td id=\"T_dc6d0_row3_col7\" class=\"data row3 col7\" >-0.004007</td>\n",
       "                        <td id=\"T_dc6d0_row3_col8\" class=\"data row3 col8\" >0.002376</td>\n",
       "                        <td id=\"T_dc6d0_row3_col9\" class=\"data row3 col9\" >-0.002410</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dc6d0_level0_row4\" class=\"row_heading level0 row4\" >passenger_count</th>\n",
       "                        <td id=\"T_dc6d0_row4_col0\" class=\"data row4 col0\" >0.000166</td>\n",
       "                        <td id=\"T_dc6d0_row4_col1\" class=\"data row4 col1\" >-0.001066</td>\n",
       "                        <td id=\"T_dc6d0_row4_col2\" class=\"data row4 col2\" >0.000169</td>\n",
       "                        <td id=\"T_dc6d0_row4_col3\" class=\"data row4 col3\" >-0.001481</td>\n",
       "                        <td id=\"T_dc6d0_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "                        <td id=\"T_dc6d0_row4_col5\" class=\"data row4 col5\" >-0.002589</td>\n",
       "                        <td id=\"T_dc6d0_row4_col6\" class=\"data row4 col6\" >-0.001395</td>\n",
       "                        <td id=\"T_dc6d0_row4_col7\" class=\"data row4 col7\" >0.035591</td>\n",
       "                        <td id=\"T_dc6d0_row4_col8\" class=\"data row4 col8\" >0.017146</td>\n",
       "                        <td id=\"T_dc6d0_row4_col9\" class=\"data row4 col9\" >0.002861</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dc6d0_level0_row5\" class=\"row_heading level0 row5\" >dif_latitude</th>\n",
       "                        <td id=\"T_dc6d0_row5_col0\" class=\"data row5 col0\" >0.144987</td>\n",
       "                        <td id=\"T_dc6d0_row5_col1\" class=\"data row5 col1\" >-0.136213</td>\n",
       "                        <td id=\"T_dc6d0_row5_col2\" class=\"data row5 col2\" >0.133518</td>\n",
       "                        <td id=\"T_dc6d0_row5_col3\" class=\"data row5 col3\" >-0.126487</td>\n",
       "                        <td id=\"T_dc6d0_row5_col4\" class=\"data row5 col4\" >-0.002589</td>\n",
       "                        <td id=\"T_dc6d0_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "                        <td id=\"T_dc6d0_row5_col6\" class=\"data row5 col6\" >0.923415</td>\n",
       "                        <td id=\"T_dc6d0_row5_col7\" class=\"data row5 col7\" >-0.001876</td>\n",
       "                        <td id=\"T_dc6d0_row5_col8\" class=\"data row5 col8\" >-0.000871</td>\n",
       "                        <td id=\"T_dc6d0_row5_col9\" class=\"data row5 col9\" >0.007177</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dc6d0_level0_row6\" class=\"row_heading level0 row6\" >dif_longitude</th>\n",
       "                        <td id=\"T_dc6d0_row6_col0\" class=\"data row6 col0\" >0.154172</td>\n",
       "                        <td id=\"T_dc6d0_row6_col1\" class=\"data row6 col1\" >-0.126502</td>\n",
       "                        <td id=\"T_dc6d0_row6_col2\" class=\"data row6 col2\" >0.138657</td>\n",
       "                        <td id=\"T_dc6d0_row6_col3\" class=\"data row6 col3\" >-0.116139</td>\n",
       "                        <td id=\"T_dc6d0_row6_col4\" class=\"data row6 col4\" >-0.001395</td>\n",
       "                        <td id=\"T_dc6d0_row6_col5\" class=\"data row6 col5\" >0.923415</td>\n",
       "                        <td id=\"T_dc6d0_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "                        <td id=\"T_dc6d0_row6_col7\" class=\"data row6 col7\" >-0.002651</td>\n",
       "                        <td id=\"T_dc6d0_row6_col8\" class=\"data row6 col8\" >-0.000960</td>\n",
       "                        <td id=\"T_dc6d0_row6_col9\" class=\"data row6 col9\" >0.006947</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dc6d0_level0_row7\" class=\"row_heading level0 row7\" >dia_semana</th>\n",
       "                        <td id=\"T_dc6d0_row7_col0\" class=\"data row7 col0\" >0.002333</td>\n",
       "                        <td id=\"T_dc6d0_row7_col1\" class=\"data row7 col1\" >-0.003780</td>\n",
       "                        <td id=\"T_dc6d0_row7_col2\" class=\"data row7 col2\" >0.002700</td>\n",
       "                        <td id=\"T_dc6d0_row7_col3\" class=\"data row7 col3\" >-0.004007</td>\n",
       "                        <td id=\"T_dc6d0_row7_col4\" class=\"data row7 col4\" >0.035591</td>\n",
       "                        <td id=\"T_dc6d0_row7_col5\" class=\"data row7 col5\" >-0.001876</td>\n",
       "                        <td id=\"T_dc6d0_row7_col6\" class=\"data row7 col6\" >-0.002651</td>\n",
       "                        <td id=\"T_dc6d0_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "                        <td id=\"T_dc6d0_row7_col8\" class=\"data row7 col8\" >-0.087571</td>\n",
       "                        <td id=\"T_dc6d0_row7_col9\" class=\"data row7 col9\" >-0.000010</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dc6d0_level0_row8\" class=\"row_heading level0 row8\" >hora</th>\n",
       "                        <td id=\"T_dc6d0_row8_col0\" class=\"data row8 col0\" >-0.002262</td>\n",
       "                        <td id=\"T_dc6d0_row8_col1\" class=\"data row8 col1\" >0.002227</td>\n",
       "                        <td id=\"T_dc6d0_row8_col2\" class=\"data row8 col2\" >-0.002691</td>\n",
       "                        <td id=\"T_dc6d0_row8_col3\" class=\"data row8 col3\" >0.002376</td>\n",
       "                        <td id=\"T_dc6d0_row8_col4\" class=\"data row8 col4\" >0.017146</td>\n",
       "                        <td id=\"T_dc6d0_row8_col5\" class=\"data row8 col5\" >-0.000871</td>\n",
       "                        <td id=\"T_dc6d0_row8_col6\" class=\"data row8 col6\" >-0.000960</td>\n",
       "                        <td id=\"T_dc6d0_row8_col7\" class=\"data row8 col7\" >-0.087571</td>\n",
       "                        <td id=\"T_dc6d0_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "                        <td id=\"T_dc6d0_row8_col9\" class=\"data row8 col9\" >-0.004456</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_dc6d0_level0_row9\" class=\"row_heading level0 row9\" >fare_amount</th>\n",
       "                        <td id=\"T_dc6d0_row9_col0\" class=\"data row9 col0\" >0.002182</td>\n",
       "                        <td id=\"T_dc6d0_row9_col1\" class=\"data row9 col1\" >-0.002081</td>\n",
       "                        <td id=\"T_dc6d0_row9_col2\" class=\"data row9 col2\" >0.002457</td>\n",
       "                        <td id=\"T_dc6d0_row9_col3\" class=\"data row9 col3\" >-0.002410</td>\n",
       "                        <td id=\"T_dc6d0_row9_col4\" class=\"data row9 col4\" >0.002861</td>\n",
       "                        <td id=\"T_dc6d0_row9_col5\" class=\"data row9 col5\" >0.007177</td>\n",
       "                        <td id=\"T_dc6d0_row9_col6\" class=\"data row9 col6\" >0.006947</td>\n",
       "                        <td id=\"T_dc6d0_row9_col7\" class=\"data row9 col7\" >-0.000010</td>\n",
       "                        <td id=\"T_dc6d0_row9_col8\" class=\"data row9 col8\" >-0.004456</td>\n",
       "                        <td id=\"T_dc6d0_row9_col9\" class=\"data row9 col9\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24091da69d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_corr= pd.DataFrame(array_corr, columns=inputCols, index=inputCols)\n",
    "mask = ~(pdf_corr>-0.3) | ~(pdf_corr<0.3)\n",
    "round(pdf_corr,10).style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observación:\n",
    "###### La variable a predecir fare_amount itnee muy baja correlación con las demás variables. Su mayor correlación es con passenger_count y hora. Pero si observamos correlación entre las demás variables. Definitivamente no podemos utilizar un modelo lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de la data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasamos toda la data a Pandas\n",
    "pandasData = dfspark_sample.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manera alternativa de pasar la data a Pandas\n",
    "# import pandas as pd\n",
    "# from pyspark.sql import DataFrame\n",
    "\n",
    "# # Wrapper for seamless Spark's serialisation\n",
    "# def spark_to_pandas(spark_df: DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     PySpark toPandas realisation using mapPartitions\n",
    "#     much faster than vanilla version\n",
    "#     fork: https://gist.github.com/lucidyan/1e5d9e490a101cdc1c2ed901568e082b\n",
    "#     origin: https://gist.github.com/joshlk/871d58e01417478176e7\n",
    "#     :param spark_df:\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def _map_to_pandas(rdds) -> list:\n",
    "#         \"\"\" Needs to be here due to pickling issues \"\"\"\n",
    "#         return [pd.DataFrame(list(rdds))]\n",
    "\n",
    "#     def _to_pandas(df: DataFrame, n_partitions: int = None) -> pd.DataFrame:\n",
    "#         \"\"\"\n",
    "#         Returns the contents of `df` as a local `pandas.DataFrame` in a speedy fashion. The DataFrame is\n",
    "#         repartitioned if `n_partitions` is passed.\n",
    "#         :param df:\n",
    "#         :param n_partitions:\n",
    "#         :return:\n",
    "#         \"\"\"\n",
    "#         if n_partitions is not None:\n",
    "#             df = df.repartition(n_partitions)\n",
    "#         df_pand = df.rdd.mapPartitions(_map_to_pandas).collect()  # type: pd.DataFrame\n",
    "#         df_pand = pd.concat(df_pand)\n",
    "#         df_pand.columns = df.columns\n",
    "#         return df_pand\n",
    "\n",
    "#     return _to_pandas(spark_df)\n",
    "\n",
    "# pandasData = spark_to_pandas(dfspark_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostrando la data\n",
    "display(pandasData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"ticks\" , color_codes = True)\n",
    "var = [\"dia_semana\"]\n",
    "# 1 inches = 96px\n",
    "g = sns.pairplot(pandasData[:10], vars=var, diag_kind=\"hist\", hue='dia_semana', height=4, aspect=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cuanto de la variable objetivo va variando segun los dias de la semana\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "carac1=pandasData['dia_semana']\n",
    "objet=pandasData['fare_amount']\n",
    "plt.plot(carac1, objet, 'o')\n",
    "plt.xlabel(\"Característica dia de la semana\")\n",
    "plt.ylabel(\"Objetivo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#como los pasajeros se distribuyen a traves de las horas\n",
    "pandasData.groupby('hora')['passenger_count'].sum().plot(kind='barh',legend='Reverse',figsize=(10,10))\n",
    "plt.xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#como se reparten los pasajeros en funcion de la hora\n",
    "pandasData.passenger_count.groupby(pandasData.hora).sum().plot(kind='pie',cmap='Paired',figsize=(12,8))\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dispersion de las características\n",
    "caracteristicas=pandasData[['fare_amount','pickup_longitude','pickup_latitude','dropoff_longitude']]\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "g= sns.pairplot(caracteristicas,hue='fare_amount',palette='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.lmplot(x='passenger_count',y='hora',data=caracteristicas,palette='Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relación entre dos caracteristicas vista como tendencia lineal\n",
    "g=sns.lmplot(x='passenger_count',y='hora',hue='dia_semana',data=caracteristicas,palette='Set1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportamos  La Dta  en un formato CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exportar la data a un formato csv\n",
    "pandasData.to_csv(\"newDatapandas.csv\",encoding = 'utf-8',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\frank\\anaconda3\\lib\\site-packages (0.16)\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paquetes pára la creacion de arbol\n",
    "#y manipulacion de archivos\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#para poder graficar el arbol de decision\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data =  pd.read_csv(\"newDatapandas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dif_latitude</th>\n",
       "      <th>dif_longitude</th>\n",
       "      <th>distancia</th>\n",
       "      <th>dia_semana</th>\n",
       "      <th>hora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.00</td>\n",
       "      <td>2015-03-12 23:14:59 UTC</td>\n",
       "      <td>-73.993141</td>\n",
       "      <td>40.727940</td>\n",
       "      <td>-73.996613</td>\n",
       "      <td>40.744530</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016590</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>1.868306</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.00</td>\n",
       "      <td>2013-08-21 08:38:06 UTC</td>\n",
       "      <td>-73.964837</td>\n",
       "      <td>40.769933</td>\n",
       "      <td>-73.983462</td>\n",
       "      <td>40.761655</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>0.018625</td>\n",
       "      <td>1.819197</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.50</td>\n",
       "      <td>2014-01-23 18:40:00 UTC</td>\n",
       "      <td>-74.001017</td>\n",
       "      <td>40.746352</td>\n",
       "      <td>-73.990873</td>\n",
       "      <td>40.739497</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>0.010144</td>\n",
       "      <td>1.145462</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.10</td>\n",
       "      <td>2011-12-24 14:03:24 UTC</td>\n",
       "      <td>-73.982433</td>\n",
       "      <td>40.768137</td>\n",
       "      <td>-73.989684</td>\n",
       "      <td>40.776138</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0.007251</td>\n",
       "      <td>1.079354</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.00</td>\n",
       "      <td>2012-10-14 23:24:00 UTC</td>\n",
       "      <td>-73.990358</td>\n",
       "      <td>40.740377</td>\n",
       "      <td>-74.000850</td>\n",
       "      <td>40.733955</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.010492</td>\n",
       "      <td>1.136704</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219168</th>\n",
       "      <td>5.70</td>\n",
       "      <td>2009-11-16 10:36:05 UTC</td>\n",
       "      <td>-73.991241</td>\n",
       "      <td>40.744892</td>\n",
       "      <td>-73.977219</td>\n",
       "      <td>40.755458</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.014022</td>\n",
       "      <td>1.666461</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219169</th>\n",
       "      <td>2.50</td>\n",
       "      <td>2014-02-26 19:44:39 UTC</td>\n",
       "      <td>-73.944647</td>\n",
       "      <td>40.751585</td>\n",
       "      <td>-73.944613</td>\n",
       "      <td>40.751624</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219170</th>\n",
       "      <td>3.30</td>\n",
       "      <td>2012-01-06 19:33:00 UTC</td>\n",
       "      <td>-74.005272</td>\n",
       "      <td>40.727898</td>\n",
       "      <td>-74.000565</td>\n",
       "      <td>40.728908</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>0.412344</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219171</th>\n",
       "      <td>49.57</td>\n",
       "      <td>2010-12-13 19:11:00 UTC</td>\n",
       "      <td>-73.785532</td>\n",
       "      <td>40.648295</td>\n",
       "      <td>-73.980030</td>\n",
       "      <td>40.760702</td>\n",
       "      <td>5</td>\n",
       "      <td>0.112407</td>\n",
       "      <td>0.194498</td>\n",
       "      <td>20.622059</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219172</th>\n",
       "      <td>8.50</td>\n",
       "      <td>2014-07-25 00:39:00 UTC</td>\n",
       "      <td>-73.976618</td>\n",
       "      <td>40.764692</td>\n",
       "      <td>-73.995085</td>\n",
       "      <td>40.755213</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.018467</td>\n",
       "      <td>1.879400</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2219173 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fare_amount          pickup_datetime  pickup_longitude  \\\n",
       "0               8.00  2015-03-12 23:14:59 UTC        -73.993141   \n",
       "1              10.00  2013-08-21 08:38:06 UTC        -73.964837   \n",
       "2               5.50  2014-01-23 18:40:00 UTC        -74.001017   \n",
       "3               6.10  2011-12-24 14:03:24 UTC        -73.982433   \n",
       "4               5.00  2012-10-14 23:24:00 UTC        -73.990358   \n",
       "...              ...                      ...               ...   \n",
       "2219168         5.70  2009-11-16 10:36:05 UTC        -73.991241   \n",
       "2219169         2.50  2014-02-26 19:44:39 UTC        -73.944647   \n",
       "2219170         3.30  2012-01-06 19:33:00 UTC        -74.005272   \n",
       "2219171        49.57  2010-12-13 19:11:00 UTC        -73.785532   \n",
       "2219172         8.50  2014-07-25 00:39:00 UTC        -73.976618   \n",
       "\n",
       "         pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0              40.727940         -73.996613         40.744530   \n",
       "1              40.769933         -73.983462         40.761655   \n",
       "2              40.746352         -73.990873         40.739497   \n",
       "3              40.768137         -73.989684         40.776138   \n",
       "4              40.740377         -74.000850         40.733955   \n",
       "...                  ...                ...               ...   \n",
       "2219168        40.744892         -73.977219         40.755458   \n",
       "2219169        40.751585         -73.944613         40.751624   \n",
       "2219170        40.727898         -74.000565         40.728908   \n",
       "2219171        40.648295         -73.980030         40.760702   \n",
       "2219172        40.764692         -73.995085         40.755213   \n",
       "\n",
       "         passenger_count  dif_latitude  dif_longitude  distancia  dia_semana  \\\n",
       "0                      2      0.016590       0.003471   1.868306           4   \n",
       "1                      1      0.008278       0.018625   1.819197           3   \n",
       "2                      1      0.006855       0.010144   1.145462           4   \n",
       "3                      1      0.008001       0.007251   1.079354           6   \n",
       "4                      1      0.006422       0.010492   1.136704           7   \n",
       "...                  ...           ...            ...        ...         ...   \n",
       "2219168                1      0.010566       0.014022   1.666461           1   \n",
       "2219169                1      0.000039       0.000034   0.005198           3   \n",
       "2219170                1      0.001010       0.004707   0.412344           5   \n",
       "2219171                5      0.112407       0.194498  20.622059           1   \n",
       "2219172                3      0.009479       0.018467   1.879400           5   \n",
       "\n",
       "         hora  \n",
       "0          23  \n",
       "1           8  \n",
       "2          18  \n",
       "3          14  \n",
       "4          23  \n",
       "...       ...  \n",
       "2219168    10  \n",
       "2219169    19  \n",
       "2219170    19  \n",
       "2219171    19  \n",
       "2219172     0  \n",
       "\n",
       "[2219173 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificamos la data\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regresion lineal simple\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se entablece las variables predictoras y obejtivos\n",
    "# se establece las columnas\n",
    "columnas_float = [\"pickup_longitude\",\"pickup_latitude\",\"dropoff_longitude\",\"dropoff_latitude\",\n",
    "                 \"passenger_count\",\"dif_latitude\",\"dif_longitude\",\"dia_semana\", \"hora\"]\n",
    "#extraccion de datos predictores\n",
    "predictors = new_data[columnas_float]\n",
    "#extraccion de dato objetivo\n",
    "target = new_data[\"fare_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se indican las etiquetas de las variable predictoras y objetivos\n",
    "predictors_label = [\"pickup_longitude\",\"pickup_latitude\",\"dropoff_longitude\",\"dropoff_latitude\",\n",
    "                 \"passenger_count\",\"dif_latitude\",\"dif_longitude\",\"dia_semana\", \"hora\"]\n",
    "\n",
    "target_label =[\"fare_amount\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crealas varibales para el entrenamiento del arbol y las varibales de prueba\n",
    "#split data ito 80% train and 205 test\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors,target,test_size =0.2,random_state =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo= LinearRegression()\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 12.022867125515502\n",
      "********************\n",
      "Coeficiente: [('pickup_longitude', 0.01035106792875126), ('pickup_latitude', 0.045202582525908336), ('dropoff_longitude', -0.009432561889370139), ('dropoff_latitude', -0.05272154785493377), ('passenger_count', 0.091047889521833), ('dif_latitude', 0.13218122117422187), ('dif_longitude', 0.025501763534595438), ('dia_semana', -0.013999422034540106), ('hora', -0.03041801194768527)]\n",
      "********************\n",
      "Coeficiente de determinación R^2: 8.475222682480243e-05\n"
     ]
    }
   ],
   "source": [
    "# Información del modelo\n",
    "# ==============================================================================\n",
    "print(\"Intercept:\", modelo.intercept_)\n",
    "print(\"*\"*20)\n",
    "print(\"Coeficiente:\", list(zip(predictors.columns, modelo.coef_.flatten(), )))\n",
    "print(\"*\"*20)\n",
    "print(\"Coeficiente de determinación R^2:\", modelo.score(predictors, target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.28684855 11.51851139 11.24084948 11.82788421 11.0391551  11.42507307\n",
      " 11.20018212 11.67110882 11.5474798  11.84089346]\n",
      "\n",
      "El error (rmse) de test es: 9.765045399049507\n"
     ]
    }
   ],
   "source": [
    "#Una vez entrenado el modelo se envia la capacidad predictiva empleando el conjunto test\n",
    "\n",
    "\n",
    "# Error de test del modelo \n",
    "# ==============================================================================\n",
    "predicciones = modelo.predict(X_test)\n",
    "print(predicciones[0:10,])\n",
    "\n",
    "rmse = mean_squared_error(\n",
    "        y_true  = y_test,\n",
    "        y_pred  = predicciones,\n",
    "        squared = False\n",
    "       )\n",
    "print(\"\")\n",
    "print(f\"El error (rmse) de test es: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion lineal multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración matplotlib\n",
    "# ==============================================================================\n",
    "plt.rcParams['image.cmap'] = \"bwr\"\n",
    "#plt.rcParams['figure.dpi'] = \"100\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            fare_amount   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     13.56\n",
      "Date:                Wed, 09 Jun 2021   Prob (F-statistic):           5.01e-22\n",
      "Time:                        13:26:05   Log-Likelihood:            -9.3622e+06\n",
      "No. Observations:             1775338   AIC:                         1.872e+07\n",
      "Df Residuals:                 1775328   BIC:                         1.872e+07\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                12.0229      0.286     42.109      0.000      11.463      12.582\n",
      "pickup_longitude      0.0104      0.029      0.355      0.723      -0.047       0.068\n",
      "pickup_latitude       0.0452      0.054      0.830      0.407      -0.062       0.152\n",
      "dropoff_longitude    -0.0094      0.030     -0.318      0.750      -0.068       0.049\n",
      "dropoff_latitude     -0.0527      0.055     -0.954      0.340      -0.161       0.056\n",
      "passenger_count       0.0910      0.027      3.361      0.001       0.038       0.144\n",
      "dif_latitude          0.1322      0.056      2.368      0.018       0.023       0.242\n",
      "dif_longitude         0.0255      0.030      0.853      0.394      -0.033       0.084\n",
      "dia_semana           -0.0140      0.018     -0.767      0.443      -0.050       0.022\n",
      "hora                 -0.0304      0.005     -5.574      0.000      -0.041      -0.020\n",
      "==================================================================================\n",
      "Omnibus:                 13865613.352   Durbin-Watson:                       2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   195722390685755104.000\n",
      "Skew:                        1247.838   Prob(JB):                             0.00\n",
      "Kurtosis:                 1626618.256   Cond. No.                             960.\n",
      "==================================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X_train = sm.add_constant(X_train, prepend=True)\n",
    "modelo = sm.OLS(y_train,X_train,)\n",
    "modelo = modelo.fit()\n",
    "print(modelo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo con toadas las variables predictoras introducidas como predictores tiene R^2 bajo 0.001, que es capz de explicar solo el 0.1% de la variabilidad obeservada en el precio el p-value del modelo es (2.91e-254)\n",
    "\n",
    "\n",
    "Acorde al p-value obtenido para coeficientes parcial de regresion de dia_semana es de (0.319), esta variable no contribuye de manera sigbificativa al modelo. procedemos a entrenar de nuevo pero excluyendo el predicto  dia_semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            fare_amount   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     15.19\n",
      "Date:                Wed, 09 Jun 2021   Prob (F-statistic):           1.63e-22\n",
      "Time:                        13:26:09   Log-Likelihood:            -9.3622e+06\n",
      "No. Observations:             1775338   AIC:                         1.872e+07\n",
      "Df Residuals:                 1775329   BIC:                         1.872e+07\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                11.9623      0.274     43.599      0.000      11.425      12.500\n",
      "pickup_longitude      0.0104      0.029      0.357      0.721      -0.047       0.068\n",
      "pickup_latitude       0.0453      0.054      0.832      0.405      -0.061       0.152\n",
      "dropoff_longitude    -0.0094      0.030     -0.318      0.751      -0.068       0.049\n",
      "dropoff_latitude     -0.0527      0.055     -0.953      0.341      -0.161       0.056\n",
      "passenger_count       0.0903      0.027      3.335      0.001       0.037       0.143\n",
      "dif_latitude          0.1322      0.056      2.368      0.018       0.023       0.242\n",
      "dif_longitude         0.0255      0.030      0.854      0.393      -0.033       0.084\n",
      "hora                 -0.0300      0.005     -5.527      0.000      -0.041      -0.019\n",
      "==================================================================================\n",
      "Omnibus:                 13865616.268   Durbin-Watson:                       2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   195722869086818976.000\n",
      "Skew:                        1247.839   Prob(JB):                             0.00\n",
      "Kurtosis:                 1626620.244   Cond. No.                             922.\n",
      "==================================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.drop(columns = 'dia_semana')\n",
    "X_test  = X_test.drop(columns = 'dia_semana')\n",
    "\n",
    "# A la matriz de predictores se le tiene que añadir una columna de 1s para el\n",
    "# intercept del modelo\n",
    "X_train = sm.add_constant(X_train, prepend=True)\n",
    "modelo  = sm.OLS(endog=y_train, exog=X_train,)\n",
    "modelo  = modelo.fit()\n",
    "print(modelo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intevalos de confianza de los coficientes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>11.424531</td>\n",
       "      <td>12.500056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_longitude</th>\n",
       "      <td>-0.046799</td>\n",
       "      <td>0.067635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_latitude</th>\n",
       "      <td>-0.061428</td>\n",
       "      <td>0.152043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <td>-0.067523</td>\n",
       "      <td>0.048684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <td>-0.161013</td>\n",
       "      <td>0.055663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_count</th>\n",
       "      <td>0.037216</td>\n",
       "      <td>0.143334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dif_latitude</th>\n",
       "      <td>0.022790</td>\n",
       "      <td>0.241557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dif_longitude</th>\n",
       "      <td>-0.033056</td>\n",
       "      <td>0.084100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hora</th>\n",
       "      <td>-0.040704</td>\n",
       "      <td>-0.019394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        2.5%      97.5%\n",
       "const              11.424531  12.500056\n",
       "pickup_longitude   -0.046799   0.067635\n",
       "pickup_latitude    -0.061428   0.152043\n",
       "dropoff_longitude  -0.067523   0.048684\n",
       "dropoff_latitude   -0.161013   0.055663\n",
       "passenger_count     0.037216   0.143334\n",
       "dif_latitude        0.022790   0.241557\n",
       "dif_longitude      -0.033056   0.084100\n",
       "hora               -0.040704  -0.019394"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervalos_ci = modelo.conf_int(alpha=0.05)\n",
    "intervalos_ci.columns = ['2.5%', '97.5%']\n",
    "intervalos_ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostico de los residuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1_train =  y_train.to_numpy()\n",
    "y_1_train = y_1_train.flatten()\n",
    "prediccion_train = modelo.predict(exog = X_train)\n",
    "residuos_train   = prediccion_train - y_1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos\n",
    "# ==============================================================================\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(9, 8))\n",
    "\n",
    "axes[0, 0].scatter(y_1_train, prediccion_train, edgecolors=(0, 0, 0), alpha = 0.4)\n",
    "axes[0, 0].plot([y_1_train.min(), y_1_train.max()], [y_1_train.min(), y_1_train.max()],\n",
    "                'k--', color = 'black', lw=2)\n",
    "axes[0, 0].set_title('Valor predicho vs valor real', fontsize = 10, fontweight = \"bold\")\n",
    "axes[0, 0].set_xlabel('Real')\n",
    "axes[0, 0].set_ylabel('Predicción')\n",
    "axes[0, 0].tick_params(labelsize = 7)\n",
    "\n",
    "axes[0, 1].scatter(list(range(len(y_1_train))), residuos_train,\n",
    "                   edgecolors=(0, 0, 0), alpha = 0.4)\n",
    "axes[0, 1].axhline(y = 0, linestyle = '--', color = 'black', lw=2)\n",
    "axes[0, 1].set_title('Residuos del modelo', fontsize = 10, fontweight = \"bold\")\n",
    "axes[0, 1].set_xlabel('id')\n",
    "axes[0, 1].set_ylabel('Residuo')\n",
    "axes[0, 1].tick_params(labelsize = 7)\n",
    "\n",
    "sns.histplot(\n",
    "    data    = residuos_train,\n",
    "    stat    = \"density\",\n",
    "    kde     = True,\n",
    "    line_kws= {'linewidth': 1},\n",
    "    color   = \"firebrick\",\n",
    "    alpha   = 0.3,\n",
    "    ax      = axes[1, 0]\n",
    ")\n",
    "\n",
    "axes[1, 0].set_title('Distribución residuos del modelo', fontsize = 10,\n",
    "                     fontweight = \"bold\")\n",
    "axes[1, 0].set_xlabel(\"Residuo\")\n",
    "axes[1, 0].tick_params(labelsize = 7)\n",
    "\n",
    "\n",
    "sm.qqplot(\n",
    "    residuos_train,\n",
    "    fit   = True,\n",
    "    line  = 'q',\n",
    "    ax    = axes[1, 1], \n",
    "    color = 'firebrick',\n",
    "    alpha = 0.4,\n",
    "    lw    = 2\n",
    ")\n",
    "axes[1, 1].set_title('Q-Q residuos del modelo', fontsize = 10, fontweight = \"bold\")\n",
    "axes[1, 1].tick_params(labelsize = 7)\n",
    "\n",
    "axes[2, 0].scatter(prediccion_train, residuos_train,\n",
    "                   edgecolors=(0, 0, 0), alpha = 0.4)\n",
    "axes[2, 0].axhline(y = 0, linestyle = '--', color = 'black', lw=2)\n",
    "axes[2, 0].set_title('Residuos del modelo vs predicción', fontsize = 10, fontweight = \"bold\")\n",
    "axes[2, 0].set_xlabel('Predicción')\n",
    "axes[2, 0].set_ylabel('Residuo')\n",
    "axes[2, 0].tick_params(labelsize = 7)\n",
    "\n",
    "# Se eliminan los axes vacíos\n",
    "fig.delaxes(axes[2,1])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('Diagnóstico residuos', fontsize = 12, fontweight = \"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los residuos parecen distyribuirse de forma aleatoria en torno a cero  mantenindo aporximandamente la misma variabilidada lo largo del eje x\n",
    "por lo tanto se pudria afirmar que tiene una distrbucion normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de Normalidad\n",
    "\n",
    "Se puede comprobar si mlos residuos siguen una disctribucion normal empleando  dos test estadicticos: Shapiro-Wilk test y D'Agostino's K-squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalidad de los residuos Shapiro-Wilk test\n",
    "# ==============================================================================\n",
    "shapiro_test = stats.shapiro(residuos_train)\n",
    "shapiro_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalidad de los residuos D'Agostino's K-squared test\n",
    "# ==============================================================================\n",
    "k2, p_value = stats.normaltest(residuos_train)\n",
    "print(f\"Estadítico= {k2}, p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos datos muestran claras enviedia que los datos se distribuyen de manera normal p-value<<0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones\n",
    "\n",
    "Una vez entrenado el modelo, se  puede obtenewr predicciones para nuevos datos. los modelos de Stastmodels permiten calcular los intevalors de confianza de cada prediccion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = modelo.get_prediction(X_train).summary_frame(alpha=0.05)\n",
    "predicciones.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error de test del modelo \n",
    "# ==============================================================================\n",
    "X_test = sm.add_constant(X_test, prepend=True)\n",
    "predicciones = modelo.predict(exog = X_test)\n",
    "rmse = mean_squared_error(\n",
    "        y_true  = y_test,\n",
    "        y_pred  = predicciones,\n",
    "        squared = False\n",
    "       )\n",
    "print(\"\")\n",
    "print(f\"El error (rmse) de test es: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretaciòn\n",
    "El modelo de regresion lineal multiple :\n",
    "\n",
    "    costo =12.11337 +pickup_longitude*0.011708 +pickup_latitude*0.0082 - dropoff_longitude*0.00457 -dropoff_latitude*0.01018+passenger_count*0.40222-dif_latitude*0.00337+dif_longitude*0.015372 + hora*0.02547"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cerramos la sesión spark\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
